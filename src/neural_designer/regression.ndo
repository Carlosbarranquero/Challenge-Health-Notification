<NeuralDesignerOutput>
 <Task Title="Inputs-targets correlations" Id="8bi6dY" Name="Calculate inputs-targets correlations" Component="Data set">
  <Text Title="Task description" Id="UcZ2qc">It might be interesting to look for dependencies between single input and single target variables. This task calculates the values of the correlation coefficient between all inputs and all targets. Correlations close to 1 mean that a single target is correlated with a single input. Correlations close to 0 mean that there is not a relationship between an input and a target variables. Note that, in general, the targets depend on many inputs simultaneously. </Text>
  <Table Title="numOfSubmissions correlations table" Id="XA5Vkd">
   <Caption Id="EYQkOU">The following table shows the value of the correlations between all input and target variables. The maximum correlation (1.000000) is yield between the input variable type and the target variable numOfSubmissions. </Caption>
   <Data>Logistic\1.000000
Linear\0.585275
Linear\0.421959
Linear\0.302796
Linear\0.105716</Data>
   <RowsName>type\challenge_prize\track\challenge_duration\createdBy</RowsName>
   <ColumnsName>type\numOfSubmissions</ColumnsName>
   <RowHeadingsWidth>26</RowHeadingsWidth>
   <ColumnHeadingsWidth>12</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <BarsChart Title="numOfSubmissions top correlations chart" Id="48yNZp">
   <Caption Id="UaV69s">The next chart illustrates the dependency of the target numOfSubmissions with the input variables.
 </Caption>
   <Data>0.105716\0.302796\0.421959\0.585275\1</Data>
   <XTitle>Correlation</XTitle>
   <Names>createdBy\challenge_duration\track\challenge_prize\type</Names>
   <Maximum>1</Maximum>
   <Metadata>0.105716\0.302796\0.421959\0.585275\1</Metadata>
  </BarsChart>
 </Task>
 <Task Title="Training" Id="PsatBH" Name="Perform training" Component="Training strategy">
  <Text Title="Task description" Id="Jofa8g">The procedure used to carry out the learning process is called training(or learning) strategy. The training strategy is applied to the neural network in order to obtain the best possible loss. The type of training is determined by the way in which the adjustment of the parameters in the neural network takes place. </Text>
  <Text Title="Optimization algorithm" Id="ND7CNm">The quasi-Newton method is used here for training. It is based on Newton's method, but does not require calculation of second derivatives. Instead, the quasi-Newton method computes an approximation of the inverse Hessian at each iteration of the algorithm, by only using gradient information. </Text>
  <DoubleLineChart Title="Quasi-Newton method errors history" Id="FMtJZo">
   <Caption Id="iegDis">The following plot shows the training and selection errors in each iteration. The blue line represents the training error and the orange line represents the selection error . The initial value of the training error is 786.837, and the final value after 391 epochs is 0.564473. The initial value of the selection error is 922.707, and the final value after 391 epochs is 0.538567. </Caption>
   <X1Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17\18\19\20\21\22\23\24\25\26\27\28\29\30\31\32\33\34\35\36\37\38\39\40\41\42\43\44\45\46\47\48\49\50\51\52\53\54\55\56\57\58\59\60\61\62\63\64\65\66\67\68\69\70\71\72\73\74\75\76\77\78\79\80\81\82\83\84\85\86\87\88\89\90\91\92\93\94\95\96\97\98\99\100\101\102\103\104\105\106\107\108\109\110\111\112\113\114\115\116\117\118\119\120\121\122\123\124\125\126\127\128\129\130\131\132\133\134\135\136\137\138\139\140\141\142\143\144\145\146\147\148\149\150\151\152\153\154\155\156\157\158\159\160\161\162\163\164\165\166\167\168\169\170\171\172\173\174\175\176\177\178\179\180\181\182\183\184\185\186\187\188\189\190\191\192\193\194\195\196\197\198\199\200\201\202\203\204\205\206\207\208\209\210\211\212\213\214\215\216\217\218\219\220\221\222\223\224\225\226\227\228\229\230\231\232\233\234\235\236\237\238\239\240\241\242\243\244\245\246\247\248\249\250\251\252\253\254\255\256\257\258\259\260\261\262\263\264\265\266\267\268\269\270\271\272\273\274\275\276\277\278\279\280\281\282\283\284\285\286\287\288\289\290\291\292\293\294\295\296\297\298\299\300\301\302\303\304\305\306\307\308\309\310\311\312\313\314\315\316\317\318\319\320\321\322\323\324\325\326\327\328\329\330\331\332\333\334\335\336\337\338\339\340\341\342\343\344\345\346\347\348\349\350\351\352\353\354\355\356\357\358\359\360\361\362\363\364\365\366\367\368\369\370\371\372\373\374\375\376\377\378\379\380\381\382\383\384\385\386\387\388\389\390\391</X1Data>
   <X2Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17\18\19\20\21\22\23\24\25\26\27\28\29\30\31\32\33\34\35\36\37\38\39\40\41\42\43\44\45\46\47\48\49\50\51\52\53\54\55\56\57\58\59\60\61\62\63\64\65\66\67\68\69\70\71\72\73\74\75\76\77\78\79\80\81\82\83\84\85\86\87\88\89\90\91\92\93\94\95\96\97\98\99\100\101\102\103\104\105\106\107\108\109\110\111\112\113\114\115\116\117\118\119\120\121\122\123\124\125\126\127\128\129\130\131\132\133\134\135\136\137\138\139\140\141\142\143\144\145\146\147\148\149\150\151\152\153\154\155\156\157\158\159\160\161\162\163\164\165\166\167\168\169\170\171\172\173\174\175\176\177\178\179\180\181\182\183\184\185\186\187\188\189\190\191\192\193\194\195\196\197\198\199\200\201\202\203\204\205\206\207\208\209\210\211\212\213\214\215\216\217\218\219\220\221\222\223\224\225\226\227\228\229\230\231\232\233\234\235\236\237\238\239\240\241\242\243\244\245\246\247\248\249\250\251\252\253\254\255\256\257\258\259\260\261\262\263\264\265\266\267\268\269\270\271\272\273\274\275\276\277\278\279\280\281\282\283\284\285\286\287\288\289\290\291\292\293\294\295\296\297\298\299\300\301\302\303\304\305\306\307\308\309\310\311\312\313\314\315\316\317\318\319\320\321\322\323\324\325\326\327\328\329\330\331\332\333\334\335\336\337\338\339\340\341\342\343\344\345\346\347\348\349\350\351\352\353\354\355\356\357\358\359\360\361\362\363\364\365\366\367\368\369\370\371\372\373\374\375\376\377\378\379\380\381\382\383\384\385\386\387\388\389\390\391</X2Data>
   <Y1Data>786.84\10.659\1.1845\0.93871\0.92293\0.88855\0.88116\0.8754\0.85622\0.84694\0.84019\0.83728\0.82949\0.8265\0.82512\0.821\0.81965\0.81771\0.80971\0.80157\0.79813\0.77732\0.76415\0.73041\0.71812\0.69388\0.67953\0.66902\0.66441\0.65836\0.65281\0.64953\0.63669\0.63633\0.62993\0.62749\0.62678\0.62651\0.62621\0.62539\0.62485\0.62451\0.62427\0.62419\0.6237\0.62354\0.62349\0.6235\0.62332\0.62309\0.62303\0.62284\0.62232\0.62225\0.62209\0.62183\0.62173\0.62157\0.62144\0.62142\0.62128\0.62093\0.62084\0.62072\0.62067\0.62059\0.62046\0.62047\0.62044\0.62044\0.62044\0.62047\0.62044\0.62047\0.62047\0.62052\0.62043\0.62048\0.62021\0.62024\0.6203\0.62025\0.62019\0.62027\0.62043\0.62029\0.62022\0.62025\0.62031\0.62023\0.62026\0.62023\0.62018\0.6202\0.62012\0.62013\0.62008\0.62008\0.62009\0.62001\0.61999\0.62008\0.61997\0.62001\0.62005\0.62005\0.62002\0.62009\0.62009\0.62008\0.62\0.62005\0.62007\0.62006\0.62007\0.62\0.61997\0.61998\0.62001\0.62007\0.6201\0.61998\0.62002\0.62\0.62001\0.62001\0.62\0.62002\0.61996\0.61994\0.61992\0.61992\0.61985\0.61986\0.61987\0.6198\0.61974\0.61978\0.61973\0.61965\0.61966\0.61964\0.61963\0.61961\0.61961\0.61963\0.61963\0.61965\0.6197\0.61975\0.61975\0.61973\0.61973\0.61977\0.61975\0.61976\0.61977\0.61977\0.61976\0.61976\0.61975\0.6198\0.61984\0.61985\0.61987\0.61986\0.61987\0.61995\0.62003\0.62011\0.62007\0.62009\0.62009\0.62009\0.6201\0.62008\0.6201\0.62013\0.62007\0.62003\0.61994\0.61985\0.61969\0.6194\0.61911\0.61887\0.61868\0.61869\0.6185\0.61832\0.61824\0.61814\0.61779\0.61779\0.61758\0.61745\0.61719\0.61665\0.61645\0.6153\0.61473\0.6143\0.61394\0.61352\0.613\0.61256\0.61225\0.61147\0.61054\0.60944\0.60861\0.60728\0.60524\0.60221\0.60169\0.60059\0.59966\0.59933\0.59857\0.59754\0.59569\0.5943\0.5937\0.59306\0.59212\0.59167\0.59128\0.59098\0.59056\0.59019\0.58985\0.58959\0.58924\0.58831\0.58745\0.58656\0.58405\0.58305\0.58263\0.5823\0.58214\0.58183\0.58162\0.58139\0.58103\0.58098\0.58078\0.58079\0.58055\0.58046\0.5804\0.58043\0.58029\0.58024\0.58021\0.58015\0.57987\0.57977\0.5795\0.5793\0.57917\0.57904\0.57888\0.57878\0.57878\0.57869\0.57872\0.57866\0.57866\0.57869\0.57871\0.57873\0.57876\0.5789\0.579\0.57866\0.57843\0.57854\0.57837\0.57826\0.57822\0.5782\0.57818\0.5781\0.57811\0.57814\0.57802\0.57756\0.57714\0.57631\0.57492\0.57425\0.57334\0.57303\0.57293\0.57291\0.57309\0.57295\0.57283\0.57271\0.57267\0.57219\0.57139\0.57079\0.57048\0.57032\0.57014\0.56971\0.56903\0.56841\0.56804\0.56767\0.5675\0.56759\0.56729\0.56723\0.56709\0.567\0.56695\0.56684\0.56672\0.56662\0.56664\0.56661\0.56658\0.56641\0.56621\0.56596\0.56571\0.56544\0.56541\0.56542\0.56542\0.56538\0.56535\0.56524\0.5652\0.56522\0.56518\0.5652\0.56518\0.56518\0.56522\0.56522\0.56505\0.56502\0.56498\0.56463\0.56453\0.56452\0.5644\0.56441\0.56439\0.56438\0.56438\0.56436\0.56437\0.56437\0.56437\0.56436\0.56428\0.56429\0.56435\0.56434\0.56433\0.56433\0.56433\0.56433\0.56433\0.56434\0.56434\0.56435\0.56439\0.56446\0.56443\0.56442\0.56443\0.56446\0.56447\0.56445\0.56446\0.56446\0.56446\0.56446\0.56447\0.56447\0.56446\0.56448\0.56447\0.56448\0.56447\0.56447</Y1Data>
   <Y1Name>Training loss</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>922.71\11.824\1.3623\1.0534\1.0326\0.9605\0.94047\0.94264\0.91586\0.91694\0.9024\0.89878\0.89211\0.88881\0.89164\0.8887\0.88611\0.87747\0.86606\0.86046\0.86286\0.84318\0.83355\0.76499\0.74312\0.74011\0.72952\0.71079\0.70829\0.68125\0.68177\0.69353\0.68543\0.68587\0.65985\0.65368\0.65737\0.64847\0.6461\0.63334\0.61599\0.61937\0.60863\0.62196\0.609\0.60953\0.60783\0.6117\0.60922\0.61219\0.61533\0.61545\0.60812\0.60616\0.60636\0.60152\0.60169\0.61043\0.6089\0.6113\0.61036\0.61332\0.61284\0.61174\0.60846\0.60812\0.61026\0.60987\0.60963\0.60937\0.60925\0.60928\0.60888\0.60896\0.60961\0.6078\0.60756\0.60892\0.60925\0.60857\0.60679\0.60692\0.60719\0.60784\0.60934\0.6089\0.60847\0.60856\0.60873\0.60761\0.60839\0.60769\0.60806\0.60795\0.60772\0.60793\0.60761\0.60773\0.60817\0.60704\0.60701\0.60768\0.60783\0.60759\0.60698\0.60689\0.60648\0.60586\0.6053\0.60571\0.6067\0.60646\0.60646\0.60673\0.60685\0.60693\0.60766\0.60781\0.60758\0.60642\0.6045\0.60558\0.60746\0.60733\0.60723\0.60719\0.60736\0.6067\0.60623\0.60524\0.60505\0.60499\0.60465\0.60565\0.60547\0.60468\0.60467\0.60426\0.60492\0.60631\0.6067\0.60613\0.60635\0.60656\0.60718\0.6072\0.60722\0.60716\0.60732\0.60731\0.60749\0.60708\0.60584\0.60625\0.60645\0.60645\0.60652\0.60658\0.60643\0.60666\0.60645\0.60631\0.60641\0.60599\0.60577\0.60575\0.60582\0.60601\0.606\0.60526\0.6054\0.60552\0.60571\0.60518\0.60493\0.60517\0.60507\0.60445\0.6043\0.60329\0.60302\0.60316\0.60524\0.60677\0.60873\0.60925\0.6082\0.60832\0.60877\0.60858\0.6075\0.60709\0.61125\0.61431\0.61068\0.6075\0.60713\0.60931\0.61117\0.60982\0.60713\0.60531\0.60585\0.60648\0.60735\0.60556\0.60426\0.60376\0.60494\0.60131\0.60155\0.60297\0.61093\0.61476\0.61455\0.61615\0.62079\0.62239\0.6231\0.63398\0.63022\0.62923\0.62966\0.62728\0.62281\0.62195\0.62042\0.61982\0.61422\0.61451\0.61424\0.61217\0.61095\0.59231\0.5824\0.57725\0.58086\0.58075\0.5844\0.58175\0.58122\0.58121\0.58059\0.57697\0.57748\0.57373\0.56862\0.57268\0.57118\0.56902\0.56965\0.57083\0.56979\0.56811\0.56832\0.56631\0.56233\0.56244\0.56324\0.56005\0.55986\0.55507\0.55\0.54973\0.5487\0.54936\0.5467\0.54707\0.54715\0.5461\0.54571\0.54623\0.54534\0.5456\0.54936\0.54329\0.54259\0.54421\0.54214\0.54071\0.54019\0.5404\0.53989\0.53865\0.5395\0.53986\0.54021\0.54179\0.54395\0.54045\0.53262\0.5331\0.52851\0.53153\0.53252\0.53088\0.53018\0.52813\0.52704\0.52811\0.52952\0.53078\0.53096\0.53013\0.52897\0.52998\0.53048\0.52999\0.52993\0.52998\0.52766\0.52496\0.52523\0.5282\0.52543\0.52593\0.52877\0.52908\0.52861\0.52892\0.52933\0.52965\0.53004\0.5304\0.53039\0.53047\0.53074\0.5313\0.53217\0.53377\0.53541\0.53501\0.53436\0.53492\0.53511\0.53477\0.53488\0.53492\0.53528\0.53522\0.53533\0.53576\0.53715\0.53806\0.53806\0.53809\0.53867\0.53933\0.53877\0.53967\0.5394\0.53953\0.5394\0.53931\0.53913\0.53862\0.53859\0.5385\0.53841\0.53857\0.53912\0.53893\0.53871\0.53904\0.53907\0.53894\0.53901\0.53898\0.53893\0.53881\0.53879\0.53903\0.53903\0.53897\0.53874\0.53875\0.53868\0.53871\0.53866\0.53868\0.53867\0.53866\0.53867\0.53866\0.53868\0.53873\0.53877\0.53862\0.53857\0.53857\0.53857\0.53857</Y2Data>
   <Y2Name>Selection loss</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Epoch</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>0</XMinimum>
   <XMaximum>391</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1000</YMaximum>
  </DoubleLineChart>
  <Table Title="Quasi-Newton method results" Id="owThed">
   <Caption Id="jiWkS4">The next table shows the training results by the quasi-Newton method. They include some final states from the neural network, the loss functional and the optimization algorithm. </Caption>
   <Data>13
0.564
0.539
0.00114
391
00:00
Minimum parameters increment norm</Data>
   <RowsName>Final parameters norm\Final training error\Final selection error\Final gradient norm\Epochs number\Elapsed time\Stopping criterion</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>20</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Order selection" Id="ZsdAtT" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="WlkZe6">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="9Q87dt">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="zG6I0z">
   <Caption Id="McQCMI">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11\12</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11\12</X2Data>
   <Y1Data>0.6486\0.58814\0.52984\0.40893\0.35396\0.13636\0.31568\0.29045\0.08746\0.17957\0.074824\0.17281</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.36418\0.74667\0.28549\0.27747\0.27055\0.25027\0.24452\0.5151\0.19485\0.31092\0.31868\0.41517</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>12</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="Ww5nfE">
   <Caption Id="B5l9QM">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>9
0.0874604
0.194846
12
00:34</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="bPnWB9">
   <Caption Id="hC49GT">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 9. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\9\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="5TEmyp" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="hddqar">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="z88cmn">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="rdzWu5">
   <Caption Id="065oeZ">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8</X1Data>
   <X2Data>1\2\3\4\5\6\7\8</X2Data>
   <Y1Data>0.62471\0.58536\0.50829\0.32559\0.36629\0.23929\0.33569\0.087323</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.62892\0.63529\0.29104\0.3248\0.20734\0.27109\0.32976\0.34828</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>8</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="7D5Pd6">
   <Caption Id="cdp7w1">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>5
0.366291
0.207343
8
00:15</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="V3KQFA">
   <Caption Id="PVD49G">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 5. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\5\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="7lbLAL" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="v6xZEP">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="McdJl1">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="2Th9DI">
   <Caption Id="n8cWya">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.62471\0.59499\0.46736\0.4856\0.36315\0.245\0.23149\0.24634\0.12799\0.077531\0.10884</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.36345\0.61982\0.32059\0.41098\0.31775\0.22327\0.32297\0.31682\0.31082\0.59026\0.92386</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="HvuYfQ">
   <Caption Id="VuBcS0">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>6
0.244997
0.223274
11
00:28</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="kHKf9O">
   <Caption Id="Ti9tDz">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 6. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\6\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="5V22BM" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="o7XyLa">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="I1X2qS">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="CHJErW">
   <Caption Id="BDtJZh">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10</X2Data>
   <Y1Data>0.62469\0.55544\0.57576\0.43591\0.39217\0.33245\0.18791\0.20067\0.14137\0.20601</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.62914\0.34246\0.72778\0.24192\0.28308\0.23811\0.6346\0.28189\0.36826\0.59146</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>10</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="6p85yq">
   <Caption Id="VJohWe">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>4
0.435912
0.241916
10
00:22</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="biVnRH">
   <Caption Id="gRLcD3">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 4. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\4\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="CYnvVr" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="rZRuuI">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="O5Wlvx">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="BkJ5Hj">
   <Caption Id="aWdkGJ">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.44517\0.26396\0.28427\0.23521\0.2782\0.22764\0.23153\0.19512\0.070068\0.11725\0.13751</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.28844\0.13293\0.20049\0.17612\0.22141\0.44319\0.27157\0.17332\0.22068\0.21595\0.22111</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="3YqcxI">
   <Caption Id="wJf80x">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>2
0.263965
0.132927
11
00:39</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="U3igkX">
   <Caption Id="ypHtWw">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 3:2. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\3\2\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="COkf9D" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="nCtfYb">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="FuegAt">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="HT30nD">
   <Caption Id="vaUlSm">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10</X2Data>
   <Y1Data>0.62471\0.51736\0.49959\0.46087\0.41013\0.18827\0.17275\0.22693\0.2076\0.065572</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.62912\0.23595\0.25493\0.33204\0.29356\0.24188\0.25918\0.38383\0.21396\0.42567</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>10</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="i6iNvs">
   <Caption Id="hdOjhM">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>9
0.207595
0.213965
10
00:24</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="LSjfRE">
   <Caption Id="Rd5dZN">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 9. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\9\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Python expression" Id="6BLqpT" Name="Export Python" Component="Neural network">
  <Text Title="Task description" Id="Y9Yoh7">The predictive model takes the form of a function of the outputs with respect to the inputs. The mathematical expression represented by the model can be exported to different programming languages, in the so called production mode. The Python programming language expression has been saved in the following file: C:/Users/Artelnics2019/Desktop/Challenge Health Notification_2.0/src/approximation_model.py</Text>
 </Task>
 <Task Title="Data set" Id="QN0Ey0" Name="Report data set" Component="Data set">
  <Text Title="Task description" Id="M8cdyY">The data set contains the information for creating the predictive model. It comprises a data matrix in which columns represent variables and rows represent instances.
Variables in a data set can be of three types: The inputs will be the independent variables; the targets will be the dependent variables; the unused variables will neither be used as inputs nor as targets.
Additionally, instances can be:
Training instances, which are used to construct the model; selection instances, which are used for selecting the optimal order; testing instances, which are used to validate the functioning of the model; unused instances, which are not used at all.
</Text>
  <Table Title="Data preview table" Id="00tylf">
   <Caption Id="XrR9Wf">The next table shows a preview of the data set obtained from the file ../../data/train/csv/training_dataset.csv. Here, the number of variables is 11, and the number of instances is 2430. </Caption>
   <Data>0\1\0\0\0\9\1\0\...\1
1\1\0\0\0\9\1\0\...\3
...\...\...\...\...\...\...\...\...\...
0\1\0\0\0\30\0\1\...\1</Data>
   <RowsName>1\2\...\2430</RowsName>
   <ColumnsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\...\numOfSubmissions</ColumnsName>
   <RowHeadingsWidth>3</RowHeadingsWidth>
   <ColumnHeadingsWidth>14</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <Table Title="Variables table" Id="3HYurV">
   <Caption Id="9rPvvS">The following table depicts the names, units, descriptions and uses of all the variables in the data set. The numbers of inputs, targets and unused variables here are 10, 1, and 0, respectively. </Caption>
   <Data>type\Input
Development\Input
Data Science\Input
Quality Assurance\Input
Design\Input
challenge_duration\Input
high_freq_createdBy\Input
low_freq_createdBy\Input
medium_freq_createdBy\Input
challenge_prize\Input
numOfSubmissions\Target</Data>
   <RowsName>1\2\3\4\5\6\7\8\9\10\11</RowsName>
   <ColumnsName>Name\Use</ColumnsName>
   <RowHeadingsWidth>3</RowHeadingsWidth>
   <ColumnHeadingsWidth>15</ColumnHeadingsWidth>
   <Alignment>left</Alignment>
  </Table>
  <BarsChart Title="Variables bars chart" Id="lu2lnP">
   <Caption Id="gMWH8V">The next chart illustrates the variables use. It depicts the numbers of inputs(10), targets(1) and unused variables(0). </Caption>
   <Data>0\1\10</Data>
   <XTitle>Number</XTitle>
   <Names>Unused variables\Target variables\Input variables</Names>
   <Maximum>11</Maximum>
   <Metadata>0\1\10</Metadata>
  </BarsChart>
  <PieChart Title="Instances pie chart" Id="e4gBI5">
   <Caption Id="ZNV9lv">The following pie chart details the uses of all the instances in the data set. The total number of instances is 2430. The number of training instances is 1458 (60%), the number of selection instances is 486 (20%), the number of testing instances is 486 (20%), and the number of unused instances is 0 (0%). </Caption>
   <Data>1458\486\486\0</Data>
   <Names Id="Acb9y3">Training\Selection\Testing\Unused</Names>
  </PieChart>
  <Text Title="Missing values" Id="cjlGGT">There are not missing values in the data set. </Text>
 </Task>
 <Task Title="Neural network outputs" Id="mdszT5" Name="Calculate outputs" Component="Neural network">
  <Text Title="Task description" Id="yvQ9sI">A neural network produces a set of outputs for each set of inputs applied. The outputs depend, in turn, on the values of the parameters. </Text>
  <Table Title="Inputs-outputs table" Id="eFoepU">
   <Caption Id="08UKJ4">The next table shows the input values and their corresponding output values. The input variables are type, Development, Data Science, Quality Assurance, Design, challenge_duration, high_freq_createdBy, low_freq_createdBy, medium_freq_createdBy, challenge_prize; and the output variable is numOfSubmissions. </Caption>
   <Data>0.617695
1
0
0
0
10.049
1
0
0
1919.63
-89.0625207</Data>
   <RowsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize\numOfSubmissions</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>9</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Neural network" Id="w2cdmK" Name="Report neural network" Component="Neural network">
  <Text Title="Task description" Id="Oxe8V3">The neural network represents the predictive model. In Neural Designer neural networks allow deep architectures, which are a class of universal approximator. </Text>
  <Table Title="Inputs" Id="YSlLsH">
   <Caption Id="GXAKE7">The number of inputs is 10. The next table depicts some basic information about them, including the name, the units and the description. </Caption>
   <Data>type
Development
Data Science
Quality Assurance
Design
challenge_duration
high_freq_createdBy
low_freq_createdBy
medium_freq_createdBy
challenge_prize</Data>
   <RowsName>1\2\3\4\5\6\7\8\9\10</RowsName>
   <ColumnsName>  Name   </ColumnsName>
   <RowHeadingsWidth>3</RowHeadingsWidth>
   <ColumnHeadingsWidth>12</ColumnHeadingsWidth>
   <Alignment>left</Alignment>
  </Table>
  <Table Title="Scaling layer" Id="Taa4xn">
   <Caption Id="Hfk8V7">The size of the scaling layer is 10, the number of inputs. The scaling method for this layer is the Automatic. The following table shows the values which are used for scaling the inputs, which include the minimum, maximum, mean and standard deviation. </Caption>
   <Data>0\1\0.618\0.486
0\1\0.78\0.414
0\1\0.0856\0.28
0\1\0.023\0.15
0\1\0.111\0.314
0\368\10\15.4
0\1\0.303\0.46
0\1\0.0416\0.2
0\1\0.656\0.475
0\1e+05\1.92e+03\5.15e+03</Data>
   <RowsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</RowsName>
   <ColumnsName>Minimum\Maximum\Mean\Deviation</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <Table Title="Perceptron layers" Id="wkFIez">
   <Caption Id="uhJzNs">The number of perceptron layers in the neural network is 2. The following table depicts the size of each layer and its corresponding activation function. </Caption>
   <Data>10\9\HyperbolicTangent
9\1\Linear</Data>
   <RowsName>1\2</RowsName>
   <ColumnsName>Inputs number\Perceptrons number\Activation function</ColumnsName>
   <RowHeadingsWidth>5</RowHeadingsWidth>
   <ColumnHeadingsWidth>14</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <Table Title="Neural network parameters" Id="icuFG8">
   <Caption Id="7tTRsL">The following table shows the statistics of the parameters of the neural network. The total number of parameters is 1. </Caption>
   <Data>-9.08\6.63\-0.142\2.57</Data>
   <RowsName>Statistics</RowsName>
   <ColumnsName>Minimum\Maximum\Mean\Standard deviation</ColumnsName>
   <RowHeadingsWidth>7</RowHeadingsWidth>
   <ColumnHeadingsWidth>13</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <Table Title="Unscaling layer" Id="3Puj1Q">
   <Caption Id="7ZQM7t">The size of the unscaling layer is 1, the number of outputs. The unscaling method for this layer is the minimum and maximum. The following table shows the values which are used for scaling the inputs, which include the minimum, maximum, mean and standard deviation. </Caption>
   <Data>0\1.61e+03\18.1\88.7</Data>
   <RowsName>numOfSubmissions</RowsName>
   <ColumnsName>Minimum\Maximum\Mean\Deviation</ColumnsName>
   <RowHeadingsWidth>12</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <Table Title="Outputs table" Id="1DL1MD">
   <Caption Id="oqMO7e">The number of outputs is 1. The next table depicts some basic information about them, including the name, the units and the description. </Caption>
   <Data>numOfSubmissions</Data>
   <RowsName>1</RowsName>
   <ColumnsName>  Name   </ColumnsName>
   <RowHeadingsWidth>3</RowHeadingsWidth>
   <ColumnHeadingsWidth>12</ColumnHeadingsWidth>
   <Alignment>left</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Neural network graph" Id="bdxvvI">
   <Caption Id="QwyPoG">A graphical representation of the network architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 9. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\9\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="0adtXy" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="epNZvv">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="FkyXWY">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="KgmGlW">
   <Caption Id="Cbpg8s">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9</X2Data>
   <Y1Data>0.58985\0.55462\0.44644\0.42224\0.32104\0.21329\0.23274\0.26256\0.16513</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.57227\0.58636\0.37864\0.49005\0.26211\0.51285\0.66392\0.3871\0.58</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>9</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="5PuFdW">
   <Caption Id="iZ64OC">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>5
0.321044
0.262107
9
00:26</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="vd1xzD">
   <Caption Id="U7e3rI">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 5. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\5\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Python expression" Id="HAwjmL" Name="Export Python" Component="Neural network">
  <Text Title="Task description" Id="6plUMK">The predictive model takes the form of a function of the outputs with respect to the inputs. The mathematical expression represented by the model can be exported to different programming languages, in the so called production mode. The Python programming language expression has been saved in the following file: C:/Users/Usuario/Desktop/Challenge Health Notification_3.5/src/approximation_model_5n.py</Text>
 </Task>
 <Task Title="Order selection" Id="nfKQOJ" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="F9uYSn">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="WzE80o">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="uAFUhX">
   <Caption Id="WrGusy">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.62243\0.58774\0.4179\0.37201\0.28511\0.29252\0.17489\0.097785\0.15633\0.10763\0.14471</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.5583\0.54658\0.30905\0.3029\0.41664\0.26812\0.31464\0.60864\0.39768\0.81017\0.93495</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="ZInpwQ">
   <Caption Id="XOuUQK">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>6
0.292519
0.268117
11
00:37</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="LfPs7A">
   <Caption Id="YLYZx2">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 6. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\6\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Python expression" Id="btXov3" Name="Export Python" Component="Neural network">
  <Text Title="Task description" Id="H4GN3x">The predictive model takes the form of a function of the outputs with respect to the inputs. The mathematical expression represented by the model can be exported to different programming languages, in the so called production mode. The Python programming language expression has been saved in the following file: C:/Users/Usuario/Desktop/Challenge Health Notification_3.5/src/approximation_model_6n.py</Text>
 </Task>
 <Task Title="Order selection" Id="VMucdi" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="nqTnYZ">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="F8dIyM">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="87mGDb">
   <Caption Id="gsW4An">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.62079\0.56673\0.52284\0.54174\0.35688\0.22235\0.41849\0.37998\0.3814\0.30797\0.27698</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.56171\0.59262\0.4343\0.49458\0.26511\0.54285\0.27446\0.29553\0.28399\0.25426\0.35052</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="dIUtjW">
   <Caption Id="zB5x15">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>10
0.30797
0.254263
11
00:06</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="Ytexhz">
   <Caption Id="mOqfH4">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 10. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\10\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="OjgX4w" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="if6VBl">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="NklCAz">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="RzThNz">
   <Caption Id="Dzad8X">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.62074\0.56495\0.58267\0.49863\0.37574\0.38491\0.31003\0.31125\0.34666\0.37197\0.30495</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.55908\0.58587\0.50579\0.55581\0.27156\0.21424\0.33384\0.30083\0.19325\0.34665\0.42927</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="Bck8pe">
   <Caption Id="qQhBfw">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>9
0.34666
0.193254
11
00:06</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="m8AsKj">
   <Caption Id="bgqbVS">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 9. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\9\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Python expression" Id="3Yelq5" Name="Export Python" Component="Neural network">
  <Text Title="Task description" Id="KojExo">The predictive model takes the form of a function of the outputs with respect to the inputs. The mathematical expression represented by the model can be exported to different programming languages, in the so called production mode. The Python programming language expression has been saved in the following file: C:/Users/Artelnics2019/Desktop/Challenge Health Notification_4/src/approximation_model_9n.py</Text>
 </Task>
 <Task Title="Filtered data" Id="zNthu5" Name="Filter data" Component="Data set">
  <Text Title="Filtered data results" Id="6jd95C">There are not instances to be filtered in the data set. </Text>
 </Task>
 <Task Title="Outliers" Id="euhZ8g" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="Aco7jo">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Table Title="Outliers instances table" Id="RkRrkW">
   <Caption Id="n7rAka">The next table lists the number of outliers found for each variable. The cleaning parameter here was  3. The number of instances that have set to unused is 306. The 12.5926% of the total. </Caption>
   <Data>0
0
0
0
0
144
0
0
0
110
184</Data>
   <RowsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize\numOfSubmissions</RowsName>
   <ColumnsName>Outliers number</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>11</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Outliers" Id="2XPhqJ" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="rh4q9y">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Table Title="Outliers instances table" Id="Ue0f8x">
   <Caption Id="p4eCrN">The next table lists the number of outliers found for each variable. The cleaning parameter here was  2. The number of instances that have set to unused is 123. The 5.79096% of the total. </Caption>
   <Data>0
0
0
0
0
42
0
0
0
21
76</Data>
   <RowsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize\numOfSubmissions</RowsName>
   <ColumnsName>Outliers number</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>11</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Model selection" Id="F6PKch" Name="Report model selection" Component="Model selection">
  <Text Title="Task description" Id="7bdB9o">Model selection is applied to find a neural network with a topology that optimizes the error on new data. There are two different types of algorithms for model selection: Order selection algorithms and input selection algorithms. Order selection algorithms are used to find the optimal number of hidden neurons in the network. Inputs selection algorithms are responsible for finding the optimal subset of input variables. </Text>
  <Table Title="Inputs selection algorithm" Id="A0qjWP">
   <Caption Id="TgIWdW">The inputs selection algorithm chosen for this application is growing inputs. With this method, the inputs are added progressively based on their correlations with the targets. </Caption>
   <Data>Number of trials for each neural network.\3
Tolerance for the selection error in the training of the algorithm.\0.01
Goal value for the selection error.\0
Maximum number of iterations at which the selection error increases.\10
Maximum number of inputs in the neural network.\10
Minimum value for the correlations to be considered.\0
Maximum value for the correlations to be considered.\1
Maximum number of iterations to perform the algorithm.\100
Maximum time for the inputs selection algorithm.\3600
Plot a graph with the training errors of each iteration.\true
Plot a graph with the selection errors of each iteration.\true</Data>
   <RowsName>Trials number\Tolerance\Selection loss goal\Maximum selection failures\Maximum inputs number\Minimum correlation\Maximum correlation\Maximum iterations number\Maximum time\Plot training loss history\Plot selection error history</RowsName>
   <ColumnsName>Description\Value</ColumnsName>
   <RowHeadingsWidth>21</RowHeadingsWidth>
   <ColumnHeadingsWidth>25</ColumnHeadingsWidth>
   <Alignment>center</Alignment>
  </Table>
  <Table Title="Order selection algorithm" Id="5VVBjp">
   <Caption Id="pME480">The order selection algorithm chosen for this application is incremental order. This method start with the minimum order and adds a given number of perceptrons in each iteration. </Caption>
   <Data>Number of minimum hidden perceptrons to be evaluated.\1
Number of maximum hidden perceptrons to be evaluated.\20
Number of hidden perceptrons added in each iteration.\1
Number of trials for each neural network.\3
Tolerance for the selection error in the trainings of the algorithm.\0.01
Goal value for the selection error.\0
Maximum number of iterations at which the selection error increases.\5
Maximum number of iterations to perform the algorithm.\1000
Maximum time for the order selection algorithm.\3600
Plot a graph with the training error of each iteration.\true
Plot a graph with the selection error of each iteration.\true</Data>
   <RowsName>Minimum order\Maximum order\Step\Trials number\Tolerance\Selection loss goal\Maximum selection failures\Maximum iterations number\Maximum time\Plot training error history\Plot selection error history</RowsName>
   <ColumnsName>Description\Value</ColumnsName>
   <RowHeadingsWidth>21</RowHeadingsWidth>
   <ColumnHeadingsWidth>25</ColumnHeadingsWidth>
   <Alignment>center</Alignment>
  </Table>
 </Task>
 <Task Title="Order selection" Id="4w3irz" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="uPEnSN">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="fdLjUN">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="3KXrhK">
   <Caption Id="4EEhib">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10</X2Data>
   <Y1Data>0.48693\0.46353\0.44024\0.42218\0.41457\0.40443\0.40244\0.39303\0.37617\0.38301</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.58943\0.55692\0.51346\0.51812\0.52349\0.54526\0.49712\0.47532\0.51442\0.51543</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>10</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="Tkq6Fv">
   <Caption Id="Cvnxmt">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>8
0.39303
0.475315
10
00:03</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="COyrnD">
   <Caption Id="cRLzB7">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 8. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\8\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="2BJ73N" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="ej1nGz">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="LjXqWo">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="XBgy2B">
   <Caption Id="9jaNmq">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.56537\0.48971\0.44548\0.42651\0.42275\0.41389\0.38996\0.37869\0.38048\0.39104\0.37495</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.61196\0.53663\0.49036\0.52982\0.48289\0.53549\0.47637\0.49512\0.50611\0.49322\0.54403</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="zpvO19">
   <Caption Id="Djx6b6">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>7
0.389964
0.476372
11
00:04</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="V3onr0">
   <Caption Id="NXuB0V">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 7. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\7\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Outliers" Id="FsUHUR" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="I4yjh3">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Table Title="Outliers instances table" Id="vd8kIq">
   <Caption Id="OYFI0F">The next table lists the number of outliers found for each variable. The cleaning parameter here was  1. The number of instances that have set to unused is 249. The 12.3757% of the total. </Caption>
   <Data>0
0
0
0
0
111
0
0
0
78
152</Data>
   <RowsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize\numOfSubmissions</RowsName>
   <ColumnsName>Outliers number</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>11</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Outliers" Id="a6gs6u" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="ZTnssj">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Text Title="Outliers results" Id="pMfm3G">The data has not outliers. </Text>
 </Task>
 <Task Title="Outliers" Id="RPYISi" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="0wSKrM">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Table Title="Outliers instances table" Id="e1bfUZ">
   <Caption Id="aAj8wC">The next table lists the number of outliers found for each variable. The cleaning parameter here was  2. The number of instances that have set to unused is 109. The 6.0321% of the total. </Caption>
   <Data>0
0
0
0
0
39
0
0
0
18
67</Data>
   <RowsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize\numOfSubmissions</RowsName>
   <ColumnsName>Outliers number</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>11</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Training" Id="ij8nEM" Name="Perform training" Component="Training strategy">
  <Text Title="Task description" Id="Hkzf4g">The procedure used to carry out the learning process is called training(or learning) strategy. The training strategy is applied to the neural network in order to obtain the best possible loss. The type of training is determined by the way in which the adjustment of the parameters in the neural network takes place. </Text>
  <Text Title="Optimization algorithm" Id="7VJpqD">The quasi-Newton method is used here for training. It is based on Newton's method, but does not require calculation of second derivatives. Instead, the quasi-Newton method computes an approximation of the inverse Hessian at each iteration of the algorithm, by only using gradient information. </Text>
  <DoubleLineChart Title="Quasi-Newton method errors history" Id="48uvoS">
   <Caption Id="gqPKa0">The following plot shows the training and selection errors in each iteration. The blue line represents the training error and the orange line represents the selection error . The initial value of the training error is 3.49341, and the final value after 81 epochs is 0.373373. The initial value of the selection error is 3.1398, and the final value after 81 epochs is 0.450545. </Caption>
   <X1Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17\18\19\20\21\22\23\24\25\26\27\28\29\30\31\32\33\34\35\36\37\38\39\40\41\42\43\44\45\46\47\48\49\50\51\52\53\54\55\56\57\58\59\60\61\62\63\64\65\66\67\68\69\70\71\72\73\74\75\76\77\78\79\80\81</X1Data>
   <X2Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17\18\19\20\21\22\23\24\25\26\27\28\29\30\31\32\33\34\35\36\37\38\39\40\41\42\43\44\45\46\47\48\49\50\51\52\53\54\55\56\57\58\59\60\61\62\63\64\65\66\67\68\69\70\71\72\73\74\75\76\77\78\79\80\81</X2Data>
   <Y1Data>3.4934\1.3616\0.78694\0.61831\0.5286\0.44473\0.42772\0.41236\0.40416\0.40236\0.39886\0.39599\0.39443\0.39281\0.39152\0.38992\0.38855\0.38745\0.38637\0.38532\0.38463\0.38349\0.382\0.38121\0.38087\0.38032\0.37905\0.37848\0.37816\0.37775\0.37716\0.37659\0.37619\0.37593\0.37581\0.37549\0.37536\0.37517\0.37489\0.37485\0.37469\0.37448\0.37435\0.3743\0.37419\0.37399\0.37393\0.37385\0.37372\0.3737\0.37364\0.37358\0.37358\0.37357\0.37354\0.3735\0.37343\0.37341\0.37342\0.37337\0.37334\0.37334\0.37332\0.37331\0.37331\0.3733\0.3733\0.37329\0.37328\0.37329\0.37328\0.37328\0.37329\0.37328\0.37328\0.37331\0.37331\0.37333\0.37336\0.37334\0.37337\0.37337</Y1Data>
   <Y1Name>Training loss</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>3.1398\1.423\0.75632\0.61412\0.5804\0.52738\0.49771\0.46773\0.4706\0.4695\0.47441\0.46662\0.46511\0.4688\0.47052\0.4728\0.46639\0.46474\0.4621\0.45964\0.45855\0.46434\0.46602\0.46298\0.4618\0.46028\0.46468\0.46283\0.46316\0.46066\0.46293\0.46182\0.45807\0.45644\0.45847\0.45694\0.45568\0.45468\0.45433\0.45572\0.45427\0.45219\0.45179\0.45228\0.45292\0.45402\0.45423\0.45432\0.45337\0.45338\0.45314\0.45373\0.45378\0.45356\0.45386\0.45364\0.45347\0.45341\0.45371\0.45306\0.45272\0.45212\0.45208\0.45135\0.45123\0.45138\0.45111\0.45111\0.45069\0.45035\0.44993\0.45001\0.44981\0.44992\0.44989\0.44972\0.44962\0.44967\0.44927\0.44966\0.4499\0.45054</Y2Data>
   <Y2Name>Selection loss</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Epoch</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>0</XMinimum>
   <XMaximum>81</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>4</YMaximum>
  </DoubleLineChart>
  <Table Title="Quasi-Newton method results" Id="GnxrKf">
   <Caption Id="nOfNh3">The next table shows the training results by the quasi-Newton method. They include some final states from the neural network, the loss functional and the optimization algorithm. </Caption>
   <Data>20
0.373
0.451
0.00749
81
00:00
Maximum selection error increases</Data>
   <RowsName>Final parameters norm\Final training error\Final selection error\Final gradient norm\Epochs number\Elapsed time\Stopping criterion</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>20</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Order selection" Id="QV4505" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="cFeQUG">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="K08R55">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="j9E0d2">
   <Caption Id="8p9BYn">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11\12\13</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11\12\13</X2Data>
   <Y1Data>0.53921\0.46676\0.46203\0.43078\0.4089\0.41505\0.39249\0.38862\0.39303\0.37982\0.36796\0.37349\0.35775</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.6172\0.53592\0.53325\0.50496\0.49786\0.51674\0.48638\0.49075\0.55114\0.47255\0.50222\0.48379\0.50216</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>13</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="ie02ch">
   <Caption Id="KxFQ7p">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>10
0.379825
0.472554
13
00:05</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="FPcrar">
   <Caption Id="0Gy13N">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 10. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\10\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Python expression" Id="dX5BDc" Name="Export Python" Component="Neural network">
  <Text Title="Task description" Id="Jlgts8">The predictive model takes the form of a function of the outputs with respect to the inputs. The mathematical expression represented by the model can be exported to different programming languages, in the so called production mode. The Python programming language expression has been saved in the following file: C:/Users/Artelnics2019/Desktop/Challenge Health Notification_4/src/approximation_no_outliers.py</Text>
 </Task>
 <Task Title="Model selection" Id="BF7ZR5" Name="Report model selection" Component="Model selection">
  <Text Title="Task description" Id="fQzoWN">Model selection is applied to find a neural network with a topology that optimizes the error on new data. There are two different types of algorithms for model selection: Order selection algorithms and input selection algorithms. Order selection algorithms are used to find the optimal number of hidden neurons in the network. Inputs selection algorithms are responsible for finding the optimal subset of input variables. </Text>
  <Table Title="Inputs selection algorithm" Id="b2gWk4">
   <Caption Id="lIOHo4">The inputs selection algorithm chosen for this application is growing inputs. With this method, the inputs are added progressively based on their correlations with the targets. </Caption>
   <Data>Number of trials for each neural network.\3
Tolerance for the selection error in the training of the algorithm.\0.01
Goal value for the selection error.\0
Maximum number of iterations at which the selection error increases.\10
Maximum number of inputs in the neural network.\10
Minimum value for the correlations to be considered.\0
Maximum value for the correlations to be considered.\1
Maximum number of iterations to perform the algorithm.\100
Maximum time for the inputs selection algorithm.\3600
Plot a graph with the training errors of each iteration.\true
Plot a graph with the selection errors of each iteration.\true</Data>
   <RowsName>Trials number\Tolerance\Selection loss goal\Maximum selection failures\Maximum inputs number\Minimum correlation\Maximum correlation\Maximum iterations number\Maximum time\Plot training loss history\Plot selection error history</RowsName>
   <ColumnsName>Description\Value</ColumnsName>
   <RowHeadingsWidth>21</RowHeadingsWidth>
   <ColumnHeadingsWidth>25</ColumnHeadingsWidth>
   <Alignment>center</Alignment>
  </Table>
  <Table Title="Order selection algorithm" Id="t1QHfp">
   <Caption Id="FqoNpV">The order selection algorithm chosen for this application is incremental order. This method start with the minimum order and adds a given number of perceptrons in each iteration. </Caption>
   <Data>Number of minimum hidden perceptrons to be evaluated.\1
Number of maximum hidden perceptrons to be evaluated.\20
Number of hidden perceptrons added in each iteration.\1
Number of trials for each neural network.\3
Tolerance for the selection error in the trainings of the algorithm.\0.01
Goal value for the selection error.\0
Maximum number of iterations at which the selection error increases.\5
Maximum number of iterations to perform the algorithm.\1000
Maximum time for the order selection algorithm.\3600
Plot a graph with the training error of each iteration.\true
Plot a graph with the selection error of each iteration.\true</Data>
   <RowsName>Minimum order\Maximum order\Step\Trials number\Tolerance\Selection loss goal\Maximum selection failures\Maximum iterations number\Maximum time\Plot training error history\Plot selection error history</RowsName>
   <ColumnsName>Description\Value</ColumnsName>
   <RowHeadingsWidth>21</RowHeadingsWidth>
   <ColumnHeadingsWidth>25</ColumnHeadingsWidth>
   <Alignment>center</Alignment>
  </Table>
 </Task>
 <Task Title="Order selection" Id="9Rp4rq" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="icH847">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="n9ZvqW">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="gWkfTs">
   <Caption Id="UmUPQ1">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.55085\0.47032\0.44211\0.40693\0.40575\0.40605\0.38931\0.37551\0.36971\0.36987\0.36924</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.61575\0.5295\0.56167\0.47776\0.51386\0.49426\0.49698\0.45826\0.52253\0.4742\0.49644</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="0VWWST">
   <Caption Id="PlMu2c">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>8
0.375512
0.458261
11
00:04</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="yaRBUz">
   <Caption Id="APVm3Z">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 11, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 8. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\day_of_year\challenge_prize</InputsName>
   <Architecture>11\11\8\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="jXS0oJ" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="3dYHRN">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="MxmDai">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="MZwBVr">
   <Caption Id="oD6wLc">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11\12\13</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11\12\13</X2Data>
   <Y1Data>0.48511\0.46047\0.44831\0.43478\0.42101\0.4019\0.39488\0.38221\0.38004\0.3817\0.3759\0.37449\0.36177</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.56142\0.52452\0.51132\0.50831\0.49002\0.4958\0.47023\0.51338\0.48616\0.51036\0.49287\0.50908\0.52654</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>13</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="gCRTnx">
   <Caption Id="iK2dEJ">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>7
0.394878
0.470232
13
00:05</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="SHsxVC">
   <Caption Id="dAcJ6i">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 7. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\7\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="ORtljm" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="MyNKV8">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="Nu1uEk">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="DqBN87">
   <Caption Id="GR5eTW">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11\12\13</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11\12\13</X2Data>
   <Y1Data>0.48412\0.46178\0.45655\0.43284\0.41326\0.40876\0.40241\0.39027\0.38097\0.377\0.37822\0.37132\0.36959</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.5664\0.51874\0.50009\0.51979\0.49651\0.46084\0.49059\0.48579\0.47663\0.50413\0.48867\0.49183\0.49386</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>13</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="EbXESa">
   <Caption Id="jOYHmV">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>6
0.408758
0.460836
13
00:05</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="yoESX0">
   <Caption Id="07wsYS">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 6. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\6\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="otaNuH" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="2oLWY3">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="DHskDD">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="BIKoBK">
   <Caption Id="sCLivB">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11\12\13\14</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11\12\13\14</X2Data>
   <Y1Data>0.56012\0.46239\0.44241\0.43937\0.40506\0.39114\0.38993\0.38932\0.37897\0.37825\0.36962\0.37239\0.3615\0.35822</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.61726\0.50146\0.5032\0.48817\0.48867\0.46871\0.45847\0.50943\0.49952\0.48543\0.46213\0.5077\0.50661\0.50829</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>14</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="XnfzDb">
   <Caption Id="sLmPBY">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>7
0.38993
0.458472
14
00:06</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="hph7Ak">
   <Caption Id="IPVXKU">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 7. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\7\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="eZs93R" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="BWQEmn">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="JamCJx">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="ss5riN">
   <Caption Id="SNTWRb">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>10\11\12\13\14\15\16</X1Data>
   <X2Data>10\11\12\13\14\15\16</X2Data>
   <Y1Data>0.37811\0.37311\0.36217\0.36053\0.35868\0.36174\0.35659</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.46853\0.48845\0.51018\0.51473\0.47624\0.50148\0.53185</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>10</XMinimum>
   <XMaximum>16</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="95jZlH">
   <Caption Id="ZajB0N">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>10
0.378108
0.46853
7
00:05</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="DIRlAo">
   <Caption Id="ozXqlj">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 10. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\10\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="sZY8pS" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="9G6Vob">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="DuijMI">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="p0ZNox">
   <Caption Id="GPiThB">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>5\6\7\8\9\10\11\12</X1Data>
   <X2Data>5\6\7\8\9\10\11\12</X2Data>
   <Y1Data>0.40786\0.40774\0.39225\0.38504\0.3869\0.37379\0.37453\0.37238</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.47975\0.5037\0.52314\0.49529\0.51588\0.47442\0.48776\0.51198</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>5</XMinimum>
   <XMaximum>12</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="5iHbt6">
   <Caption Id="7wpHKq">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>5
0.407857
0.479753
8
00:04</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="rfYS91">
   <Caption Id="m5lKSC">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 5. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\5\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="u9va8I" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="jY8YBZ">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="mjE1wz">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="WzqJGC">
   <Caption Id="uTYQ2i">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11\12\13\14\15</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11\12\13\14\15</X2Data>
   <Y1Data>0.48663\0.48581\0.42875\0.42489\0.40556\0.4038\0.39978\0.40417\0.38535\0.38372\0.37311\0.37336\0.35503\0.35829\0.35123</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.56129\0.53466\0.50078\0.47375\0.51695\0.51332\0.47924\0.51872\0.50177\0.49884\0.48987\0.51445\0.47183\0.51906\0.52212</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>15</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="YJtEez">
   <Caption Id="M07Rrk">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>4
0.424889
0.473748
15
00:06</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="CgTls0">
   <Caption Id="dn7LGt">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 4. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\4\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Outliers" Id="GwFukO" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="qUwTgI">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Table Title="Outliers instances table" Id="x789Yf">
   <Caption Id="KzUf3t">The next table lists the number of outliers found for each variable. The cleaning parameter here was  2. The number of instances that have set to unused is 103. The 5.96065% of the total. </Caption>
   <Data>0
0
0
0
0
37
0
0
0
18
62</Data>
   <RowsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize\numOfSubmissions</RowsName>
   <ColumnsName>Outliers number</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>11</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Order selection" Id="G8BN1Y" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="jOFEm4">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="QArCWm">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="8DLeRD">
   <Caption Id="wtPifq">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10</X2Data>
   <Y1Data>0.46622\0.44629\0.44318\0.41582\0.4081\0.3985\0.38922\0.37964\0.3721\0.36991</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.58459\0.51878\0.52724\0.55369\0.53607\0.54673\0.51947\0.54525\0.52345\0.54566</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>10</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="4JqhAr">
   <Caption Id="eNB6Yo">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>2
0.446293
0.518778
10
00:03</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="vaJF5O">
   <Caption Id="2MtCY6">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 2. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\2\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Outliers" Id="QT5nla" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="fHtGxd">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Table Title="Outliers instances table" Id="Jz1Plx">
   <Caption Id="wEYVDD">The next table lists the number of outliers found for each variable. The cleaning parameter here was  2. The number of instances that have set to unused is 429. The 17.6543% of the total. </Caption>
   <Data>0
0
0
0
0
213
0
0
0
147
273</Data>
   <RowsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize\numOfSubmissions</RowsName>
   <ColumnsName>Outliers number</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>11</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Order selection" Id="qT98cy" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="Tj5i6m">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="rtLgqi">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="m19FLq">
   <Caption Id="3S9MG8">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17</X2Data>
   <Y1Data>0.68945\0.63825\0.60754\0.57718\0.57008\0.54134\0.54849\0.55299\0.53678\0.53055\0.52365\0.52727\0.51905\0.52088\0.51026\0.49954\0.50663</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.65394\0.62003\0.6288\0.58999\0.57405\0.54601\0.58689\0.57971\0.5734\0.55584\0.63566\0.63413\0.6019\0.5787\0.60387\0.56445\0.58212</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>17</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="z1lCcu">
   <Caption Id="k3Pn7L">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>6
0.541344
0.546013
17
00:08</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="rfY2Eb">
   <Caption Id="2dhKmf">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 6. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\6\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="dBG4ct" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="TwCAfF">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="emXlQa">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="uTxF7D">
   <Caption Id="nB43Pg">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17</X2Data>
   <Y1Data>0.73104\0.6363\0.60647\0.60197\0.57285\0.55323\0.55313\0.54857\0.53648\0.53193\0.52441\0.51943\0.51513\0.49687\0.49608\0.50384\0.49775</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.74131\0.69807\0.65416\0.60536\0.59472\0.57928\0.61612\0.60461\0.60764\0.56081\0.61221\0.58268\0.56699\0.60476\0.58965\0.57414\0.62461</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>17</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="oH7AOs">
   <Caption Id="2r2XV4">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>10
0.531932
0.560805
17
00:09</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="eGSlh6">
   <Caption Id="2ckae4">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 10. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\10\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Outliers" Id="crx6TT" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="aguAzr">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Text Title="Outliers results" Id="oEYppJ">The data has not outliers. </Text>
 </Task>
 <Task Title="Outliers" Id="DI6otD" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="HJxavZ">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Table Title="Outliers instances table" Id="dbqFDw">
   <Caption Id="SPof1U">The next table lists the number of outliers found for each variable. The cleaning parameter here was  3. The number of instances that have set to unused is 312. The 12.8395% of the total. </Caption>
   <Data>0
11
0
0
0
0
144
0
0
0
0
0
0
0
110
184</Data>
   <RowsName>type\legacyId\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\medium_freq_updatedBy\high_freq_updatedBy\low_freq_updatedBy\day_of_year\challenge_prize\numOfSubmissions</RowsName>
   <ColumnsName>Outliers number</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>11</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Training" Id="suTUQR" Name="Perform training" Component="Training strategy">
  <Text Title="Task description" Id="qfmB9a">The procedure used to carry out the learning process is called training(or learning) strategy. The training strategy is applied to the neural network in order to obtain the best possible loss. The type of training is determined by the way in which the adjustment of the parameters in the neural network takes place. </Text>
  <Text Title="Optimization algorithm" Id="Bsq59w">The quasi-Newton method is used here for training. It is based on Newton's method, but does not require calculation of second derivatives. Instead, the quasi-Newton method computes an approximation of the inverse Hessian at each iteration of the algorithm, by only using gradient information. </Text>
  <DoubleLineChart Title="Quasi-Newton method errors history" Id="eHZgHd">
   <Caption Id="xEHai7">The following plot shows the training and selection errors in each iteration. The blue line represents the training error and the orange line represents the selection error . The initial value of the training error is 63.0428, and the final value after 77 epochs is 0.370095. The initial value of the selection error is 53.0128, and the final value after 77 epochs is 0.473056. </Caption>
   <X1Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17\18\19\20\21\22\23\24\25\26\27\28\29\30\31\32\33\34\35\36\37\38\39\40\41\42\43\44\45\46\47\48\49\50\51\52\53\54\55\56\57\58\59\60\61\62\63\64\65\66\67\68\69\70\71\72\73\74\75\76\77</X1Data>
   <X2Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17\18\19\20\21\22\23\24\25\26\27\28\29\30\31\32\33\34\35\36\37\38\39\40\41\42\43\44\45\46\47\48\49\50\51\52\53\54\55\56\57\58\59\60\61\62\63\64\65\66\67\68\69\70\71\72\73\74\75\76\77</X2Data>
   <Y1Data>63.043\8.0886\2.687\2.033\1.6326\1.1105\0.8873\0.79755\0.73644\0.70095\0.67744\0.66893\0.66021\0.64681\0.62343\0.60478\0.59764\0.57948\0.54067\0.52804\0.52297\0.51376\0.50672\0.50012\0.49149\0.48331\0.47756\0.46921\0.45739\0.45281\0.44857\0.44236\0.43491\0.43202\0.4276\0.42311\0.42061\0.4182\0.41466\0.41221\0.40974\0.40766\0.40428\0.40145\0.39934\0.39755\0.39529\0.39317\0.39178\0.39085\0.38909\0.38737\0.38694\0.38621\0.38579\0.38525\0.38435\0.38345\0.38293\0.38232\0.38154\0.38079\0.3801\0.37963\0.37854\0.37751\0.37656\0.37611\0.37494\0.37375\0.37311\0.37304\0.37248\0.37211\0.37148\0.37114\0.37048\0.37009</Y1Data>
   <Y1Name>Training loss</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>53.013\6.4493\2.2564\1.7714\1.4437\0.95634\0.80018\0.70367\0.68721\0.63914\0.64611\0.65156\0.62517\0.60102\0.55638\0.54429\0.54217\0.52679\0.52572\0.5241\0.52629\0.50974\0.51807\0.50511\0.50508\0.49365\0.48829\0.47937\0.48191\0.47887\0.48144\0.47776\0.49524\0.50153\0.51583\0.50883\0.49514\0.49553\0.49348\0.49558\0.47821\0.49177\0.49533\0.49331\0.48429\0.47857\0.48655\0.47754\0.47795\0.48078\0.4833\0.47941\0.47606\0.47887\0.47806\0.47594\0.47344\0.47432\0.47038\0.47137\0.46935\0.46957\0.47162\0.47216\0.47158\0.47603\0.47892\0.48135\0.48772\0.48156\0.4801\0.47569\0.47764\0.47851\0.47676\0.47309\0.47093\0.47306</Y2Data>
   <Y2Name>Selection loss</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Epoch</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>0</XMinimum>
   <XMaximum>77</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>100</YMaximum>
  </DoubleLineChart>
  <Table Title="Quasi-Newton method results" Id="oPf08i">
   <Caption Id="ZPJLQz">The next table shows the training results by the quasi-Newton method. They include some final states from the neural network, the loss functional and the optimization algorithm. </Caption>
   <Data>16.8
0.37
0.473
0.0305
77
00:00
Maximum selection error increases</Data>
   <RowsName>Final parameters norm\Final training error\Final selection error\Final gradient norm\Epochs number\Elapsed time\Stopping criterion</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>20</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Order selection" Id="rbIo3W" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="tPwmcD">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="ymgu0g">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="v5l19Z">
   <Caption Id="5jdzs3">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.62905\0.50537\0.45558\0.41668\0.39514\0.39368\0.38394\0.38515\0.36399\0.3476\0.3346</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.60298\0.49255\0.46168\0.44953\0.46021\0.46518\0.48863\0.45449\0.47512\0.4719\0.50575</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="sDQKdR">
   <Caption Id="RB8pvv">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>4
0.416675
0.449526
11
00:05</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="PGQBMq">
   <Caption Id="X8j0a7">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 15, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 4. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\legacyId\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\medium_freq_updatedBy\high_freq_updatedBy\low_freq_updatedBy\day_of_year\challenge_prize</InputsName>
   <Architecture>15\15\4\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="RiEXtg" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="jpGrqj">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="B8FEKc">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="aRpBcZ">
   <Caption Id="3Bl7VF">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11\12\13</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11\12\13</X2Data>
   <Y1Data>0.49885\0.49996\0.44993\0.43642\0.42451\0.39868\0.39215\0.3865\0.37058\0.35259\0.35664\0.34891\0.35062</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.49677\0.50303\0.47903\0.49889\0.48894\0.48154\0.46429\0.48347\0.4525\0.4702\0.46798\0.45724\0.46745</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>13</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="0pKGL4">
   <Caption Id="NmedmG">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>9
0.370576
0.452502
13
00:06</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="ZUwt9J">
   <Caption Id="7EH6Em">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 15, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 9. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\legacyId\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\medium_freq_updatedBy\high_freq_updatedBy\low_freq_updatedBy\day_of_year\challenge_prize</InputsName>
   <Architecture>15\15\9\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="ZaOGmd" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="njfJay">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="Q1nXWy">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="wfc5Uk">
   <Caption Id="rUdUQO">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10</X2Data>
   <Y1Data>0.50817\0.45921\0.46816\0.42351\0.38861\0.38342\0.37601\0.37853\0.36057\0.3551</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.49349\0.47098\0.47939\0.434\0.46248\0.44398\0.45601\0.49457\0.46176\0.4741</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>10</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="WjsLLk">
   <Caption Id="dCrU68">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>4
0.423509
0.434005
10
00:05</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="KOSFSz">
   <Caption Id="4CkSzU">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 15, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 4. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\legacyId\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\medium_freq_updatedBy\high_freq_updatedBy\low_freq_updatedBy\day_of_year\challenge_prize</InputsName>
   <Architecture>15\15\4\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="OkzXT3" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="FNXxrT">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="hpadC1">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="Vft9pE">
   <Caption Id="3kr6Db">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.50132\0.48049\0.44766\0.43118\0.43605\0.38787\0.38418\0.39081\0.36844\0.35107\0.35009</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.49575\0.50271\0.46433\0.46105\0.47249\0.48094\0.47401\0.4499\0.44451\0.45583\0.4605</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="Hvb15x">
   <Caption Id="wFPfqZ">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>8
0.39081
0.449898
11
00:05</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="FIb3hp">
   <Caption Id="mwVk5z">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 15, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 8. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\legacyId\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\medium_freq_updatedBy\high_freq_updatedBy\low_freq_updatedBy\day_of_year\challenge_prize</InputsName>
   <Architecture>15\15\8\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="949Do2" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="bFvyhW">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="PElnWB">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="IX6BLz">
   <Caption Id="aLK9wj">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10</X2Data>
   <Y1Data>0.50807\0.48049\0.40896\0.42545\0.42359\0.39951\0.36967\0.37057\0.39061\0.35168</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.4943\0.46843\0.48049\0.45425\0.45937\0.51473\0.42668\0.48366\0.43118\0.44788</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>10</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="rezSBh">
   <Caption Id="uiWjAH">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>7
0.369675
0.426679
10
00:04</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="7ZfDLk">
   <Caption Id="KblFdI">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 15, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 7. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\legacyId\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\medium_freq_updatedBy\high_freq_updatedBy\low_freq_updatedBy\day_of_year\challenge_prize</InputsName>
   <Architecture>15\15\7\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="rZXf5e" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="QRDTvF">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="diLX2m">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="QpvVES">
   <Caption Id="RuOCG9">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10</X2Data>
   <Y1Data>0.60743\0.50238\0.46377\0.428\0.43071\0.41782\0.40322\0.4073\0.39578\0.38894</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.59169\0.51756\0.4614\0.46808\0.49056\0.45232\0.45739\0.46795\0.4653\0.47411</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>10</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="57qjh5">
   <Caption Id="PYgugO">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>3
0.463767
0.461396
10
00:04</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="v8VXih">
   <Caption Id="LpihMX">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 3. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\3\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="gpdHVS" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="A49O16">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="pRKotK">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="oS8R77">
   <Caption Id="IZy1um">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11\12</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11\12</X2Data>
   <Y1Data>0.52784\0.4586\0.46666\0.43069\0.43419\0.41472\0.40821\0.39826\0.39102\0.38305\0.37573\0.37629</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.50808\0.46363\0.48844\0.47317\0.46137\0.4545\0.46697\0.47383\0.46784\0.46233\0.47906\0.48219</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>12</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="UeuYet">
   <Caption Id="ACoADy">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>2
0.458601
0.463626
12
00:04</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="jST78s">
   <Caption Id="ZGTnyQ">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 2. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\2\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Order selection" Id="vhLVFM" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="4foKjN">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="pBfjoQ">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="yeWctb">
   <Caption Id="O6SP6b">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.57382\0.55398\0.4595\0.45704\0.43412\0.42334\0.40866\0.39522\0.39521\0.38747\0.3884</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.57167\0.49684\0.46405\0.47008\0.47278\0.47585\0.47416\0.46572\0.49255\0.45718\0.48555</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="z9KDoM">
   <Caption Id="27eurW">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>3
0.459502
0.464053
11
00:04</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="mHMAGy">
   <Caption Id="3HN92x">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 3. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\3\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Outliers" Id="5ReYc5" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="WdKxR8">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Table Title="Outliers instances table" Id="MJmSDn">
   <Caption Id="okdci8">The next table lists the number of outliers found for each variable. The cleaning parameter here was  3. The number of instances that have set to unused is 306. The 12.5926% of the total. </Caption>
   <Data>0
0
0
0
0
144
0
0
0
110
184</Data>
   <RowsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize\numOfSubmissions</RowsName>
   <ColumnsName>Outliers number</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>11</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Training" Id="j8ah8Z" Name="Perform training" Component="Training strategy">
  <Text Title="Task description" Id="2tYOMP">The procedure used to carry out the learning process is called training(or learning) strategy. The training strategy is applied to the neural network in order to obtain the best possible loss. The type of training is determined by the way in which the adjustment of the parameters in the neural network takes place. </Text>
  <Text Title="Optimization algorithm" Id="6h6Dx8">The quasi-Newton method is used here for training. It is based on Newton's method, but does not require calculation of second derivatives. Instead, the quasi-Newton method computes an approximation of the inverse Hessian at each iteration of the algorithm, by only using gradient information. </Text>
  <DoubleLineChart Title="Quasi-Newton method errors history" Id="06gan1">
   <Caption Id="CLTzL8">The following plot shows the training and selection errors in each iteration. The blue line represents the training error and the orange line represents the selection error . The initial value of the training error is 3.40621, and the final value after 241 epochs is 0.453472. The initial value of the selection error is 0, and the final value after 241 epochs is 0. </Caption>
   <X1Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17\18\19\20\21\22\23\24\25\26\27\28\29\30\31\32\33\34\35\36\37\38\39\40\41\42\43\44\45\46\47\48\49\50\51\52\53\54\55\56\57\58\59\60\61\62\63\64\65\66\67\68\69\70\71\72\73\74\75\76\77\78\79\80\81\82\83\84\85\86\87\88\89\90\91\92\93\94\95\96\97\98\99\100\101\102\103\104\105\106\107\108\109\110\111\112\113\114\115\116\117\118\119\120\121\122\123\124\125\126\127\128\129\130\131\132\133\134\135\136\137\138\139\140\141\142\143\144\145\146\147\148\149\150\151\152\153\154\155\156\157\158\159\160\161\162\163\164\165\166\167\168\169\170\171\172\173\174\175\176\177\178\179\180\181\182\183\184\185\186\187\188\189\190\191\192\193\194\195\196\197\198\199\200\201\202\203\204\205\206\207\208\209\210\211\212\213\214\215\216\217\218\219\220\221\222\223\224\225\226\227\228\229\230\231\232\233\234\235\236\237\238\239\240\241</X1Data>
   <X2Data>0\1\2\3\4\5\6\7\8\9\10\11\12\13\14\15\16\17\18\19\20\21\22\23\24\25\26\27\28\29\30\31\32\33\34\35\36\37\38\39\40\41\42\43\44\45\46\47\48\49\50\51\52\53\54\55\56\57\58\59\60\61\62\63\64\65\66\67\68\69\70\71\72\73\74\75\76\77\78\79\80\81\82\83\84\85\86\87\88\89\90\91\92\93\94\95\96\97\98\99\100\101\102\103\104\105\106\107\108\109\110\111\112\113\114\115\116\117\118\119\120\121\122\123\124\125\126\127\128\129\130\131\132\133\134\135\136\137\138\139\140\141\142\143\144\145\146\147\148\149\150\151\152\153\154\155\156\157\158\159\160\161\162\163\164\165\166\167\168\169\170\171\172\173\174\175\176\177\178\179\180\181\182\183\184\185\186\187\188\189\190\191\192\193\194\195\196\197\198\199\200\201\202\203\204\205\206\207\208\209\210\211\212\213\214\215\216\217\218\219\220\221\222\223\224\225\226\227\228\229\230\231\232\233\234\235\236\237\238\239\240\241</X2Data>
   <Y1Data>3.4062\0.68255\0.59319\0.49423\0.49007\0.48885\0.48846\0.48575\0.48514\0.48397\0.48396\0.48371\0.48351\0.48334\0.48299\0.48296\0.48283\0.48276\0.48227\0.48137\0.48131\0.48096\0.4798\0.47851\0.4783\0.47789\0.47771\0.47753\0.47684\0.47603\0.4758\0.47574\0.47565\0.47543\0.4753\0.4753\0.47529\0.47529\0.47508\0.47515\0.47511\0.47509\0.47511\0.4752\0.47468\0.47485\0.47445\0.47436\0.47423\0.47399\0.47403\0.4738\0.47366\0.47348\0.47352\0.47255\0.472\0.4717\0.47151\0.47108\0.47082\0.4707\0.47071\0.47062\0.47022\0.46994\0.46964\0.46914\0.46879\0.46854\0.46827\0.46824\0.46817\0.46814\0.46818\0.4681\0.46806\0.46794\0.46797\0.46795\0.46802\0.46804\0.46811\0.46824\0.46818\0.46818\0.46818\0.46823\0.46828\0.46835\0.46896\0.46916\0.46912\0.46851\0.4685\0.46855\0.46847\0.46837\0.46841\0.46856\0.46768\0.4656\0.46521\0.46368\0.46337\0.46323\0.46314\0.4631\0.46304\0.46298\0.46289\0.46284\0.4628\0.46267\0.46246\0.46232\0.46224\0.46232\0.46223\0.46231\0.4622\0.46219\0.46218\0.46207\0.46201\0.46196\0.46196\0.46199\0.46206\0.46204\0.46206\0.46226\0.4623\0.46234\0.462\0.46159\0.46144\0.46142\0.46141\0.46142\0.46137\0.46139\0.46132\0.46121\0.46114\0.46113\0.46114\0.46115\0.46114\0.46114\0.46116\0.46124\0.46146\0.46155\0.46172\0.46158\0.46156\0.46161\0.46159\0.46142\0.46139\0.4609\0.4605\0.46035\0.46009\0.45988\0.45974\0.45961\0.45962\0.45957\0.4595\0.45946\0.45939\0.45926\0.45913\0.45903\0.45903\0.45898\0.45897\0.45896\0.45894\0.45889\0.45885\0.45887\0.45894\0.45909\0.45906\0.45904\0.45912\0.45916\0.45922\0.45903\0.45881\0.45847\0.45828\0.45813\0.45746\0.45711\0.45658\0.45621\0.45623\0.45564\0.45546\0.45552\0.45531\0.45525\0.45525\0.45515\0.45495\0.45479\0.45473\0.45469\0.45466\0.45463\0.45461\0.45459\0.45457\0.45456\0.45457\0.45459\0.45455\0.45449\0.45451\0.45449\0.45449\0.45412\0.45411\0.45368\0.45376\0.45357\0.45356\0.45356\0.45355\0.45357\0.45353\0.45356\0.45354\0.45351\0.45349\0.45347\0.45347\0.45347</Y1Data>
   <Y1Name>Training loss</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0</Y2Data>
   <Y2Name>Selection loss</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Epoch</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>0</XMinimum>
   <XMaximum>241</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>4</YMaximum>
  </DoubleLineChart>
  <Table Title="Quasi-Newton method results" Id="rs9Zkc">
   <Caption Id="iPcuKH">The next table shows the training results by the quasi-Newton method. They include some final states from the neural network, the loss functional and the optimization algorithm. </Caption>
   <Data>5.73
0.453
0
0.000517
241
00:00
Gradient norm goal</Data>
   <RowsName>Final parameters norm\Final training error\Final selection error\Final gradient norm\Epochs number\Elapsed time\Stopping criterion</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>20</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Outliers" Id="eSxB1c" Name="Clean outliers" Component="Data set">
  <Text Title="Task description" Id="Mgytah">Outliers are defined as observations in the data that are abnormally distant from the others. They may be due to variability in the measurement or may indicate experimental errors. This task uses the Tukey's method, which defines an outlier as those values of the data set that fall to far from the central point, the median. The maximum distance to the center of the data that is going to be allowed is defined by the cleaning parameter. As it grows, the test becomes less sensitive to outliers but if it is too small, a lot of values will be detected as outliers. </Text>
  <Table Title="Outliers instances table" Id="z3RWMV">
   <Caption Id="YC2mW5">The next table lists the number of outliers found for each variable. The cleaning parameter here was  3. The number of instances that have set to unused is 306. The 12.5926% of the total. </Caption>
   <Data>0
0
0
0
0
144
0
0
0
110
184</Data>
   <RowsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize\numOfSubmissions</RowsName>
   <ColumnsName>Outliers number</ColumnsName>
   <RowHeadingsWidth>15</RowHeadingsWidth>
   <ColumnHeadingsWidth>11</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
 </Task>
 <Task Title="Order selection" Id="KS9BvX" Name="Perform order selection" Component="Model selection">
  <Text Title="Task description" Id="jvE6yB">The best selection is achieved by using a model whose complexity is the most appropriate to produce an adequate fit of the data. The order selection algorithm is responsible of finding the optimal number of neurons in the network. </Text>
  <Text Title="Order selection algorithm" Id="Cb8JjS">Incremental order is used here as order selection algorithm in the model selection. </Text>
  <DoubleLineChart Title="Incremental order error plot" Id="CkJmrl">
   <Caption Id="TJCNn5">The next chart shows the error history for the different subsets during the incremental order selection process. The blue line represents the training error and the orange line symbolizes the selection error. </Caption>
   <X1Data>1\2\3\4\5\6\7\8\9\10\11</X1Data>
   <X2Data>1\2\3\4\5\6\7\8\9\10\11</X2Data>
   <Y1Data>0.51302\0.47245\0.50284\0.42849\0.42647\0.41756\0.4065\0.40515\0.39312\0.39983\0.39782</Y1Data>
   <Y1Name>Training error</Y1Name>
   <Color1>#437CC0</Color1>
   <Width1>1</Width1>
   <Areas1>false</Areas1>
   <Y2Data>0.47645\0.4559\0.48532\0.45689\0.43332\0.4544\0.44809\0.45469\0.47144\0.43926\0.48782</Y2Data>
   <Y2Name>Selection error</Y2Name>
   <Color2>#FF4F4A</Color2>
   <Width2>1</Width2>
   <Areas2>false</Areas2>
   <Metadata/>
   <MetadataName/>
   <XLabel>Order</XLabel>
   <YLabel>Normalized squared error</YLabel>
   <XMinimum>1</XMinimum>
   <XMaximum>11</XMaximum>
   <YMinimum>0</YMinimum>
   <YMaximum>1</YMaximum>
  </DoubleLineChart>
  <Table Title="Incremental order results" Id="0NXVRT">
   <Caption Id="XFxSP8">The next table shows the order selection results by the incremental order algorithm. They include some final states from the neural network, the error functional and the order selection algorithm. </Caption>
   <Data>5
0.426474
0.43332
11
00:04</Data>
   <RowsName>Optimal order\Optimum training error\Optimum selection error\Iterations number\Elapsed time</RowsName>
   <ColumnsName>Value</ColumnsName>
   <RowHeadingsWidth>17</RowHeadingsWidth>
   <ColumnHeadingsWidth>6</ColumnHeadingsWidth>
   <Alignment>right</Alignment>
  </Table>
  <NeuralNetworkGraph Title="Final architecture" Id="nnKAn3">
   <Caption Id="TnRou8">A graphical representation of the resulted deep architecture is depicted next. It contains a scaling layer, a neural network and an unscaling layer. The yellow circles represent scaling neurons, the blue circles perceptron neurons and the red circles unscaling neurons. The number of inputs is 10, and the number of outputs is 1. The complexity, represented by the numbers of hidden neurons, is 5. </Caption>
   <ProjectType>Approximation</ProjectType>
   <PrincipalComponentsMethod>NoPrincipalComponents</PrincipalComponentsMethod>
   <BoundingMethod>NoBounding</BoundingMethod>
   <InputsName>type\Development\Data Science\Quality Assurance\Design\challenge_duration\high_freq_createdBy\low_freq_createdBy\medium_freq_createdBy\challenge_prize</InputsName>
   <Architecture>10\10\5\1\1\1</Architecture>
   <OutputsName>numOfSubmissions</OutputsName>
  </NeuralNetworkGraph>
 </Task>
 <Task Title="Python expression" Id="ROsbWp" Name="Export Python" Component="Neural network">
  <Text Title="Task description" Id="rKkehY">The predictive model takes the form of a function of the outputs with respect to the inputs. The mathematical expression represented by the model can be exported to different programming languages, in the so called production mode. The Python programming language expression has been saved in the following file: C:/Users/Artelnics2019/Desktop/Challenge Health Notification_4/src/approximation_model_final.py</Text>
 </Task>
</NeuralDesignerOutput>
